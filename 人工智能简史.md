# 人工智能简史

# 神经网络简史

自图灵提出“机器与智能”起，就一直有两派观点：一派认为实现人工智能必须用逻辑和符号系统，；还有一派认为通过仿造大脑可以达到人工智能，这一派是自底向上的，他们认为如果能造一台机器，模拟大脑中的神经网络，这台机器就有智能了。前一派，我想用“想啥来啥”来形容；后一派就称之为“吃啥补啥”，估计他们的思想来源于中国古代的原始思维，套一句庸俗的哲学词，前者偏唯心，后者偏唯物。这两派一直是人工智能领域里“两个阶级、两条路线”的斗争，这斗争有时还你死我活。

# 符号派

这一派看问题是自顶向下的

# 放生派

这一派是自底向上的，他们认为如果能造一台机器，模拟大脑中的神经网络，这台机器就有智能了



# 神经网络

## Hebb规则

1949年，神经心理学家赫布（Donald Hebb）出版了《行为组织学》（Organization of Behavior）。在该书中，赫布提出了被后人称为“Hebb规则”的学习机制。该规则认为，如果两个细胞总是同时激活的话，它们之间就有某种关联，同时激活的概率越高，关联度也越高。换句话说，就是“吃啥补啥”。2000年诺贝尔医学奖得主肯德尔（Eric Kandel）的动物实验也证实了Hebb规则。后来的各种无监督机器学习算法或多或少都是Hebb规则的变种。

## 感知机

罗森布拉特在理论上证明了单层神经网络在处理线性可分的模式识别问题时，可以收敛，并以此为基础做了若干“感知机”有学习能力的实验。

## Adaline可适应性算法

维德罗（Widrow）是斯坦福大学教授，在罗森布拉特刚提出“感知机”时，他就提出了Adaline可适应性算法。Adaline和感知机很相似，也是机器学习的鼻祖模型之一。

## “后向传播”（back-propagation）

1974年，哈佛大学的一篇博士论文证明了在神经网络多加一层，并且利用“后向传播”（back-propagation）学习方法，可以解决XOR问题。这篇论文的作者是沃波斯（Paul Werbos），他后来得到了IEEE神经网络学会的先驱奖。沃波斯这篇文章刚发表时并没引起多少重视，那时正是神经网络研究的低谷，文章不合时宜。

## 霍普菲尔德网络

神经网络在20世纪80年代的复兴归功于物理学家霍普菲尔德（John Hopfield）。1982年，那时在加州理工学院担任生物物理教授的霍普菲尔德，提出了一种新的神经网络，可以解决一大类模式识别问题，还可以给出一类组合优化问题的近似解。这种神经网络模型后来被称为霍普菲尔德网络。

## 连接主义运动

### 代表人物

- 鲁梅尔哈特（David Rumelhart）
- 麦克利兰德（JamesMcLelland）
- 辛顿（GeoffreyHinton）

PDP（Parallel and DistributedProcessing）的著名文集（分两卷）。此书的出版给认知科学和计算机科学吹了股大风，被后起的神经网络新秀称为“圣经”。

20世纪80年代的“神经网络”就像20世纪90年代的互联网、后来的Web 2.0和眼下的“大数据”。

连接主义运动也培养了一堆新人，并使得加州大学圣地亚哥分校的认知科学系成为同类系科的佼佼者。鲁梅尔哈特后转往斯坦福大学任教，2011年不幸死于已挣扎多年的神经退化疾病。乔丹（Michael Jordan）就是他的学生，而**吴恩达（Andrew Ng）**又是乔丹的学生。鲁梅尔哈特人虽离世，但香火没灭。

**辛顿**则先转往卡内基梅隆大学，最终到加拿大多伦多大学计算机系任教。辛顿现在可是神经网络领域最牛的人了。

**诺维格**在加入谷歌之前曾是加州大学伯克利分校的计算机教授，他对两派都了如指掌，在学术界和工业界都被尊重，他写的《人工智能》是最流行的教科书。他的观点似乎被更多的人接受

## 深度学习

神经网络在20世纪80年代的光芒被后来的互联网掩盖了。但这几年，恰恰又是互联网产生的海量数据给了神经网络更大的机会。人工智能学者在计算机系曾经是最抬不起头的，这几年却人人都变成了公共知识分子。而人工智能领域最火的词儿就是“深度学习”。神经网络由一层一层的神经元构成。层数越多，就越深，所谓深度学习就是用很多层神经元构成的神经网络达到机器学习的功能。

理论上说，如果一层网络是一个函数的话，多层网络就是多个函数的嵌套。网络越深，表达能力越强，但伴随而来的训练复杂性也急剧加大。目前对神经网络各种形态所对应的计算复杂性的研究并不多，从业者也以工程师、心理学家和统计学家为多。

辛顿是深度学习的先驱，他和学生在2006年发表的两篇文章开辟了这个新领域，其中登在《科学》上的那篇提出了降维和逐层预训练的方法，使得深度网络的实用化成为可能。深度神经网络最后几层的每个节点都可对应于某些概念。这是神经网络的一大进步，貌似为“吃啥补啥”找到了科学根据，调和了与“符号派”的矛盾。至于符号派买不买账，就是另一回事了。

深度学习的实测效果很好。辛顿一直用深度信任网络做图像识别，在2012年举办的图像识别国际大赛ILSVRC（ImageNet Large Scale VisualRecognition Challenge）上，辛顿团队的SuperVision以绝对领先的成绩击败众竞争对手拔得头筹。该比赛用1000万张图像训练，用15万张图像测试，目标是识别测试图像到底是动物，是花儿，还是船，等等。在2012年前，普遍的错误率在26%。但SuperVision头次参赛就把错误率控制在了15%之下，以超过10%的惊人优势遥遥领先。2009年，微软研究院的邓力小组开始和辛顿合作，用深度学习加上隐马尔科夫模型开发可实用的语音识别和同声翻译系统，2011年取得突破。2012年，微软负责研发的拉希德（Rick Rashid）在天津举行的一次会议上现场演示，他用英文演讲，机器用中文实时翻译，甚至中文合成的声音跟他自己的声色都非常相像。微软把这一成果迅速产品化，微软收购的聊天工具Skype首先得益，整合了实时语音翻译的功能。此后，语音识别问题已经被认为彻底解决了。现在即使开源的软件都可以达到很高的识别率。中国的腾讯和科大讯飞等也都有此类产品。

### 机器学习主要研究团队

- 辛顿（GeoffreyHinton）
- 蒙特利尔的班乔（Yoshua Bengio）
- 阿尔伯塔的萨顿（RichardSutton）

2012年，时任斯坦福大学人工智能实验室主任的吴恩达和谷歌合作建造了一个当时最大的神经网络，这是谷歌神秘的X实验室的一个计划。网络上一度疯传的谷歌猫脸识别就是用的这个参数多达十七亿的神经网络。后来，吴恩达在斯坦福大学又搞了个更大的神经网络，参数高达一百一十二亿。人脑的神经连接有一百万万亿个。从计算能力上说，如果这个人工神经网络要能接近大脑，每个人工神经元必须达到一万个大脑神经元的功能。这个神经网络会用到大量的图形处理芯片GPU, GPU一度是模拟神经网络的完美硬件，因为每个GPU芯片内都有大量的小核心。这和神经网络的大规模并行性天然相似。硬件的进步让以往不可能的成为了可能。GPU的厂商Nvidia股票也一路飙升。对计算量的需求是没有止境的，新的芯片技术也被用到深度学习中，先是有人试图用FPGA（可编程阵列）和ASIC实现各种深度学习算法，后来谷歌推出了专用芯片TPU。

### 参考文献指南

- McCulloch and Pitts (1943)
- Rosenblatt (1958)
- Minsky and Papert (1969)
- Wang and Raj (2017)

**McCulloch and Pitts (1943)**今天读来仍有意义。而Rosenblatt (1958)和Minsky and Papert (1969)则没必要花功夫去仔细研读了，只要知道结果就行了，就如想知道牛顿第二定律不一定非得读他的原著《自然哲学的数学原理》，一本中学物理教科书足矣。**Wang and Raj (2017)**是详实的深度学习历史，但那是写给内行人看的。**Hopefield**开创了神经网络研究的新气象，Hopfield (1982)讲离散型Hopfield网络，Hopfield and Tank(1985)讲连续型Hopfield网络。如果有理工背景，这两篇文章都不难懂，值得一看。深度学习的文献真不需要“指南”，各种深度的“深度”都烂大街了。

f



# 放生派

这一派是自底向上的，他们认为如果能造一台机器，模拟大脑中的神经网络，这台机器就有智能了

