# 人工智能简史

# 神经网络简史

自图灵提出“机器与智能”起，就一直有两派观点：一派认为实现人工智能必须用逻辑和符号系统，；还有一派认为通过仿造大脑可以达到人工智能，这一派是自底向上的，他们认为如果能造一台机器，模拟大脑中的神经网络，这台机器就有智能了。前一派，我想用“想啥来啥”来形容；后一派就称之为“吃啥补啥”，估计他们的思想来源于中国古代的原始思维，套一句庸俗的哲学词，前者偏唯心，后者偏唯物。这两派一直是人工智能领域里“两个阶级、两条路线”的斗争，这斗争有时还你死我活。

# 符号派

这一派看问题是自顶向下的

## Hebb规则

1949年，神经心理学家赫布（Donald Hebb）出版了《行为组织学》（Organization of Behavior）。在该书中，赫布提出了被后人称为“Hebb规则”的学习机制。该规则认为，如果两个细胞总是同时激活的话，它们之间就有某种关联，同时激活的概率越高，关联度也越高。换句话说，就是“吃啥补啥”。2000年诺贝尔医学奖得主肯德尔（Eric Kandel）的动物实验也证实了Hebb规则。后来的各种无监督机器学习算法或多或少都是Hebb规则的变种。

## 感知机

罗森布拉特在理论上证明了单层神经网络在处理线性可分的模式识别问题时，可以收敛，并以此为基础做了若干“感知机”有学习能力的实验。

## Adaline可适应性算法

维德罗（Widrow）是斯坦福大学教授，在罗森布拉特刚提出“感知机”时，他就提出了Adaline可适应性算法。Adaline和感知机很相似，也是机器学习的鼻祖模型之一。

## “后向传播”（back-propagation）

1974年，哈佛大学的一篇博士论文证明了在神经网络多加一层，并且利用“后向传播”（back-propagation）学习方法，可以解决XOR问题。这篇论文的作者是沃波斯（Paul Werbos），他后来得到了IEEE神经网络学会的先驱奖。沃波斯这篇文章刚发表时并没引起多少重视，那时正是神经网络研究的低谷，文章不合时宜。

## 霍普菲尔德网络

神经网络在20世纪80年代的复兴归功于物理学家霍普菲尔德（John Hopfield）。1982年，那时在加州理工学院担任生物物理教授的霍普菲尔德，提出了一种新的神经网络，可以解决一大类模式识别问题，还可以给出一类组合优化问题的近似解。这种神经网络模型后来被称为霍普菲尔德网络。

## 连接主义运动

### 代表人物

- 鲁梅尔哈特（David Rumelhart）
- 麦克利兰德（JamesMcLelland）
- 辛顿（GeoffreyHinton）

PDP（Parallel and DistributedProcessing）的著名文集（分两卷）。此书的出版给认知科学和计算机科学吹了股大风，被后起的神经网络新秀称为“圣经”。

20世纪80年代的“神经网络”就像20世纪90年代的互联网、后来的Web 2.0和眼下的“大数据”

f



# 放生派

这一派是自底向上的，他们认为如果能造一台机器，模拟大脑中的神经网络，这台机器就有智能了

